{
  "env_path_toactivate": "/home/polete/Documents/DRL-tflite-KV260-env/bin",
  "size_actuator_array": 1,
  "size_obs_array_per_UDP": 4,
  "total_descarte": 0,
  "total_descarte_used": 0,
  "message_type": 1,
  "scalar_reward": 1,
  "reward_type": "",
  "training": true,
  "evaluation": false,
  "eval_freq": 5000,
  "n_eval_episodes": 5,
  "episode_length": 40,
  "total_episodes": 10000,
  "create_new_model": true,
  "log_dir_template": "logs_debug_eval/model_PPO_{}",
  "load_model_path": "/scratch/polsm/011-DRL-experimental/AFC-DRL-experiment-v3/09-test-CTA-DRL/logs_debug_eval/model_PPO_20250703-1926",
  "crio_ip": "172.22.11.2",
  "hp_ip": "172.22.11.1",
  "debug_ip": "127.0.0.1",
  "udp_port_send": 61557,
  "udp_port_recv": 61555,
  "DEBUG": false,
  "debugging_IP": true,
  "action_min": -10,
  "action_max": 10,
  "n_steps": 160,
  "batch_size": 40,
  "n_epochs": 10,
  "algo_type": "PPO",
  "ppo_learning_rate": 0.005,
  "ppo_log_std_init": 2.0,
  "ppo_gamma":0.5,
  "ppo_normalize_advantage": true,
  "ddpg_learning_rate": 0.05,
  "buffer_size": 100000,
  "tau": 0.005,
  "ou_sigma": 0.2,
  "delta_t": 0.01,
  "actor_layers": [8, 8],
  "critic_layers": [8, 8]
}
